{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from deeppavlov import build_model, configs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-17 08:34:28.89 INFO in 'deeppavlov.core.data.utils'['utils'] at line 97: Downloading from http://files.deeppavlov.ai/deeppavlov_data/classifiers/insults_kaggle_torch_bert_v5.tar.gz to C:\\Users\\nephelim\\.deeppavlov\\models\\insults_kaggle_torch_bert_v5.tar.gz\n",
      "100%|██████████| 1.09G/1.09G [02:00<00:00, 9.04MB/s]\n",
      "2024-11-17 08:36:29.141 INFO in 'deeppavlov.core.data.utils'['utils'] at line 284: Extracting C:\\Users\\nephelim\\.deeppavlov\\models\\insults_kaggle_torch_bert_v5.tar.gz archive into C:\\Users\\nephelim\\.deeppavlov\\models\\classifiers\n",
      "2024-11-17 08:36:37.796 INFO in 'deeppavlov.core.data.utils'['utils'] at line 97: Downloading from http://files.deeppavlov.ai/datasets/insults_data.tar.gz to C:\\Users\\nephelim\\.deeppavlov\\insults_data.tar.gz\n",
      "100%|██████████| 682k/682k [00:00<00:00, 2.42MB/s]\n",
      "2024-11-17 08:36:38.531 INFO in 'deeppavlov.core.data.utils'['utils'] at line 284: Extracting C:\\Users\\nephelim\\.deeppavlov\\insults_data.tar.gz archive into C:\\Users\\nephelim\\.deeppavlov\\downloads\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2024-11-17 08:36:54.462 WARNING in 'deeppavlov.core.models.torch_model'['torch_model'] at line 96: Unable to place component TorchTransformersClassifierModel on GPU, since no CUDA GPUs are available. Using CPU.\n",
      "c:\\Users\\nephelim\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\deeppavlov\\core\\models\\torch_model.py:134: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(weights_path, map_location=self.device)\n",
      "2024-11-17 08:36:55.962 ERROR in 'deeppavlov.core.common.params'['params'] at line 108: Exception in <class 'deeppavlov.models.torch_bert.torch_transformers_classifier.TorchTransformersClassifierModel'>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nephelim\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\deeppavlov\\core\\common\\params.py\", line 102, in from_params\n",
      "    component = obj(**dict(config_params, **kwargs))\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\nephelim\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\deeppavlov\\models\\torch_bert\\torch_transformers_classifier.py\", line 121, in __init__\n",
      "    super().__init__(model, **kwargs)\n",
      "  File \"c:\\Users\\nephelim\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\deeppavlov\\core\\models\\torch_model.py\", line 84, in __init__\n",
      "    self.load()\n",
      "  File \"c:\\Users\\nephelim\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\deeppavlov\\core\\models\\torch_model.py\", line 144, in load\n",
      "    self.model.load_state_dict(model_state)\n",
      "  File \"c:\\Users\\nephelim\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 2584, in load_state_dict\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Error(s) in loading state_dict for BertForSequenceClassification:\n",
      "\tUnexpected key(s) in state_dict: \"bert.embeddings.position_ids\". \n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for BertForSequenceClassification:\n\tUnexpected key(s) in state_dict: \"bert.embeddings.position_ids\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdeeppavlov\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m build_model, configs\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Загрузка модели для классификации оскорблений\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfigs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclassifiers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minsults_kaggle_bert\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Пример текста для классификации\u001b[39;00m\n\u001b[0;32m      7\u001b[0m test_texts \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mТы ужасный человек!\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mКакой прекрасный день!\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\nephelim\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\deeppavlov\\core\\commands\\infer.py:55\u001b[0m, in \u001b[0;36mbuild_model\u001b[1;34m(config, mode, load_trained, install, download)\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m         log\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNo \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msave_path\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m parameter for the \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m component, so \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mload_path\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m will not be renewed\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     53\u001b[0m                     \u001b[38;5;241m.\u001b[39mformat(component_config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclass_name\u001b[39m\u001b[38;5;124m'\u001b[39m, component_config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mref\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUNKNOWN\u001b[39m\u001b[38;5;124m'\u001b[39m))))\n\u001b[1;32m---> 55\u001b[0m component \u001b[38;5;241m=\u001b[39m \u001b[43mfrom_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcomponent_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m component_config:\n\u001b[0;32m     58\u001b[0m     model\u001b[38;5;241m.\u001b[39m_components_dict[component_config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m]] \u001b[38;5;241m=\u001b[39m component\n",
      "File \u001b[1;32mc:\\Users\\nephelim\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\deeppavlov\\core\\common\\params.py:102\u001b[0m, in \u001b[0;36mfrom_params\u001b[1;34m(params, mode, **kwargs)\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmode\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m spec\u001b[38;5;241m.\u001b[39margs \u001b[38;5;241m+\u001b[39m spec\u001b[38;5;241m.\u001b[39mkwonlyargs \u001b[38;5;129;01mor\u001b[39;00m spec\u001b[38;5;241m.\u001b[39mvarkw \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    100\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmode\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m mode\n\u001b[1;32m--> 102\u001b[0m component \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconfig_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    104\u001b[0m     _refs[config_params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m]] \u001b[38;5;241m=\u001b[39m component\n",
      "File \u001b[1;32mc:\\Users\\nephelim\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\deeppavlov\\models\\torch_bert\\torch_transformers_classifier.py:121\u001b[0m, in \u001b[0;36mTorchTransformersClassifierModel.__init__\u001b[1;34m(self, n_classes, pretrained_bert, multilabel, return_probas, attention_probs_keep_prob, hidden_keep_prob, bert_config_file, is_binary, num_special_tokens, **kwargs)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_special_tokens \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    119\u001b[0m     model\u001b[38;5;241m.\u001b[39mresize_token_embeddings(\u001b[38;5;28mlen\u001b[39m(tokenizer) \u001b[38;5;241m+\u001b[39m num_special_tokens)\n\u001b[1;32m--> 121\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nephelim\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\deeppavlov\\core\\models\\torch_model.py:84\u001b[0m, in \u001b[0;36mTorchModel.__init__\u001b[1;34m(self, model, device, optimizer, optimizer_parameters, learning_rate_drop_patience, learning_rate_drop_div, load_before_drop, min_learning_rate, clip_norm, *args, **kwargs)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_learning_rate \u001b[38;5;241m=\u001b[39m min_learning_rate\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclip_norm \u001b[38;5;241m=\u001b[39m clip_norm\n\u001b[1;32m---> 84\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;66;03m# we need to switch to eval mode here because by default it's in `train` mode.\u001b[39;00m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;66;03m# But in case of `interact/build_model` usage, we need to have model in eval mode.\u001b[39;00m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39meval()\n",
      "File \u001b[1;32mc:\\Users\\nephelim\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\deeppavlov\\core\\models\\torch_model.py:144\u001b[0m, in \u001b[0;36mTorchModel.load\u001b[1;34m(self, fname, *args, **kwargs)\u001b[0m\n\u001b[0;32m    142\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mmodule\u001b[38;5;241m.\u001b[39mload_state_dict(model_state)\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 144\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:  \u001b[38;5;66;03m# TODO: remove this try-except after hf models deep update\u001b[39;00m\n\u001b[0;32m    146\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mload_state_dict(optimizer_state)\n",
      "File \u001b[1;32mc:\\Users\\nephelim\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2584\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[1;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[0;32m   2576\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[0;32m   2577\u001b[0m             \u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m   2578\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   2579\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)\n\u001b[0;32m   2580\u001b[0m             ),\n\u001b[0;32m   2581\u001b[0m         )\n\u001b[0;32m   2583\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 2584\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m   2585\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   2586\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)\n\u001b[0;32m   2587\u001b[0m         )\n\u001b[0;32m   2588\u001b[0m     )\n\u001b[0;32m   2589\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for BertForSequenceClassification:\n\tUnexpected key(s) in state_dict: \"bert.embeddings.position_ids\". "
     ]
    }
   ],
   "source": [
    "from deeppavlov import build_model, configs\n",
    "\n",
    "# Загрузка модели для классификации оскорблений\n",
    "model = build_model(configs.classifiers.insults_kaggle_bert, download=True)\n",
    "\n",
    "# Пример текста для классификации\n",
    "test_texts = [\"Ты ужасный человек!\", \"Какой прекрасный день!\"]\n",
    "\n",
    "# Классификация текста\n",
    "predicted_labels = model(test_texts)\n",
    "print(predicted_labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-17 08:52:01.873 INFO in 'deeppavlov.core.data.utils'['utils'] at line 97: Downloading from http://files.deeppavlov.ai/v1/classifiers/rusentiment_convers_bert/rusentiment_convers_bert_torch.tar.gz to C:\\Users\\nephelim\\.deeppavlov\\models\\classifiers\\rusentiment_convers_bert_torch.tar.gz\n",
      "100%|██████████| 1.52G/1.52G [02:48<00:00, 9.01MB/s]\n",
      "2024-11-17 08:54:50.616 INFO in 'deeppavlov.core.data.utils'['utils'] at line 284: Extracting C:\\Users\\nephelim\\.deeppavlov\\models\\classifiers\\rusentiment_convers_bert_torch.tar.gz archive into C:\\Users\\nephelim\\.deeppavlov\\models\\classifiers\\rusentiment_convers_bert_torch\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b84a883f3004c4bb484cf82aac62cd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/24.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nephelim\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\file_download.py:139: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\nephelim\\.cache\\huggingface\\hub\\models--DeepPavlov--rubert-base-cased-conversational. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e6760abd5c4451a841965ff8833ec5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/642 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9d7d039476e445b9754a869e9ebc82b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/1.40M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea59d5b4877d4fb6903a8e0cf8dc737c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf5711e332674f078c8eb4ed5cfef6e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/714M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at DeepPavlov/rubert-base-cased-conversational and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2024-11-17 08:56:26.307 WARNING in 'deeppavlov.core.models.torch_model'['torch_model'] at line 96: Unable to place component TorchTransformersClassifierModel on GPU, since no CUDA GPUs are available. Using CPU.\n",
      "2024-11-17 08:56:29.263 ERROR in 'deeppavlov.core.common.params'['params'] at line 108: Exception in <class 'deeppavlov.models.torch_bert.torch_transformers_classifier.TorchTransformersClassifierModel'>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nephelim\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\deeppavlov\\core\\common\\params.py\", line 102, in from_params\n",
      "    component = obj(**dict(config_params, **kwargs))\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\nephelim\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\deeppavlov\\models\\torch_bert\\torch_transformers_classifier.py\", line 121, in __init__\n",
      "    super().__init__(model, **kwargs)\n",
      "  File \"c:\\Users\\nephelim\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\deeppavlov\\core\\models\\torch_model.py\", line 84, in __init__\n",
      "    self.load()\n",
      "  File \"c:\\Users\\nephelim\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\deeppavlov\\core\\models\\torch_model.py\", line 144, in load\n",
      "    self.model.load_state_dict(model_state)\n",
      "  File \"c:\\Users\\nephelim\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 2584, in load_state_dict\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Error(s) in loading state_dict for BertForSequenceClassification:\n",
      "\tUnexpected key(s) in state_dict: \"bert.embeddings.position_ids\". \n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for BertForSequenceClassification:\n\tUnexpected key(s) in state_dict: \"bert.embeddings.position_ids\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdeeppavlov\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m build_model, configs\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Загрузка модели для анализа настроений на русском языке\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfigs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclassifiers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrusentiment_convers_bert\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Пример текста для классификации\u001b[39;00m\n\u001b[0;32m      7\u001b[0m test_texts \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mЯ люблю программирование.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mЭтот фильм был ужасен.\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\nephelim\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\deeppavlov\\core\\commands\\infer.py:55\u001b[0m, in \u001b[0;36mbuild_model\u001b[1;34m(config, mode, load_trained, install, download)\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m         log\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNo \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msave_path\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m parameter for the \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m component, so \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mload_path\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m will not be renewed\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     53\u001b[0m                     \u001b[38;5;241m.\u001b[39mformat(component_config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclass_name\u001b[39m\u001b[38;5;124m'\u001b[39m, component_config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mref\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUNKNOWN\u001b[39m\u001b[38;5;124m'\u001b[39m))))\n\u001b[1;32m---> 55\u001b[0m component \u001b[38;5;241m=\u001b[39m \u001b[43mfrom_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcomponent_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m component_config:\n\u001b[0;32m     58\u001b[0m     model\u001b[38;5;241m.\u001b[39m_components_dict[component_config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m]] \u001b[38;5;241m=\u001b[39m component\n",
      "File \u001b[1;32mc:\\Users\\nephelim\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\deeppavlov\\core\\common\\params.py:102\u001b[0m, in \u001b[0;36mfrom_params\u001b[1;34m(params, mode, **kwargs)\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmode\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m spec\u001b[38;5;241m.\u001b[39margs \u001b[38;5;241m+\u001b[39m spec\u001b[38;5;241m.\u001b[39mkwonlyargs \u001b[38;5;129;01mor\u001b[39;00m spec\u001b[38;5;241m.\u001b[39mvarkw \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    100\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmode\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m mode\n\u001b[1;32m--> 102\u001b[0m component \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconfig_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    104\u001b[0m     _refs[config_params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m]] \u001b[38;5;241m=\u001b[39m component\n",
      "File \u001b[1;32mc:\\Users\\nephelim\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\deeppavlov\\models\\torch_bert\\torch_transformers_classifier.py:121\u001b[0m, in \u001b[0;36mTorchTransformersClassifierModel.__init__\u001b[1;34m(self, n_classes, pretrained_bert, multilabel, return_probas, attention_probs_keep_prob, hidden_keep_prob, bert_config_file, is_binary, num_special_tokens, **kwargs)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_special_tokens \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    119\u001b[0m     model\u001b[38;5;241m.\u001b[39mresize_token_embeddings(\u001b[38;5;28mlen\u001b[39m(tokenizer) \u001b[38;5;241m+\u001b[39m num_special_tokens)\n\u001b[1;32m--> 121\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nephelim\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\deeppavlov\\core\\models\\torch_model.py:84\u001b[0m, in \u001b[0;36mTorchModel.__init__\u001b[1;34m(self, model, device, optimizer, optimizer_parameters, learning_rate_drop_patience, learning_rate_drop_div, load_before_drop, min_learning_rate, clip_norm, *args, **kwargs)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_learning_rate \u001b[38;5;241m=\u001b[39m min_learning_rate\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclip_norm \u001b[38;5;241m=\u001b[39m clip_norm\n\u001b[1;32m---> 84\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;66;03m# we need to switch to eval mode here because by default it's in `train` mode.\u001b[39;00m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;66;03m# But in case of `interact/build_model` usage, we need to have model in eval mode.\u001b[39;00m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39meval()\n",
      "File \u001b[1;32mc:\\Users\\nephelim\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\deeppavlov\\core\\models\\torch_model.py:144\u001b[0m, in \u001b[0;36mTorchModel.load\u001b[1;34m(self, fname, *args, **kwargs)\u001b[0m\n\u001b[0;32m    142\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mmodule\u001b[38;5;241m.\u001b[39mload_state_dict(model_state)\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 144\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:  \u001b[38;5;66;03m# TODO: remove this try-except after hf models deep update\u001b[39;00m\n\u001b[0;32m    146\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mload_state_dict(optimizer_state)\n",
      "File \u001b[1;32mc:\\Users\\nephelim\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2584\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[1;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[0;32m   2576\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[0;32m   2577\u001b[0m             \u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m   2578\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   2579\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)\n\u001b[0;32m   2580\u001b[0m             ),\n\u001b[0;32m   2581\u001b[0m         )\n\u001b[0;32m   2583\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 2584\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m   2585\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   2586\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)\n\u001b[0;32m   2587\u001b[0m         )\n\u001b[0;32m   2588\u001b[0m     )\n\u001b[0;32m   2589\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for BertForSequenceClassification:\n\tUnexpected key(s) in state_dict: \"bert.embeddings.position_ids\". "
     ]
    }
   ],
   "source": [
    "from deeppavlov import build_model, configs\n",
    "\n",
    "# Загрузка модели для анализа настроений на русском языке\n",
    "model = build_model(configs.classifiers.rusentiment_convers_bert, download=True)\n",
    "\n",
    "# Пример текста для классификации\n",
    "test_texts = [\"Я люблю программирование.\", \"Этот фильм был ужасен.\"]\n",
    "\n",
    "# Классификация текста\n",
    "predicted_labels = model(test_texts)\n",
    "print(predicted_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-17 08:57:06.867 INFO in 'deeppavlov.download'['download'] at line 138: Skipped http://files.deeppavlov.ai/v1/classifiers/rusentiment_bert/rusentiment_bert_torch.tar.gz download because of matching hashes\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2024-11-17 08:57:07.889 WARNING in 'deeppavlov.core.models.torch_model'['torch_model'] at line 96: Unable to place component TorchTransformersClassifierModel on GPU, since no CUDA GPUs are available. Using CPU.\n",
      "2024-11-17 08:57:12.817 ERROR in 'deeppavlov.core.common.params'['params'] at line 108: Exception in <class 'deeppavlov.models.torch_bert.torch_transformers_classifier.TorchTransformersClassifierModel'>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nephelim\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\deeppavlov\\core\\common\\params.py\", line 102, in from_params\n",
      "    component = obj(**dict(config_params, **kwargs))\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\nephelim\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\deeppavlov\\models\\torch_bert\\torch_transformers_classifier.py\", line 121, in __init__\n",
      "    super().__init__(model, **kwargs)\n",
      "  File \"c:\\Users\\nephelim\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\deeppavlov\\core\\models\\torch_model.py\", line 84, in __init__\n",
      "    self.load()\n",
      "  File \"c:\\Users\\nephelim\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\deeppavlov\\core\\models\\torch_model.py\", line 144, in load\n",
      "    self.model.load_state_dict(model_state)\n",
      "  File \"c:\\Users\\nephelim\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 2584, in load_state_dict\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Error(s) in loading state_dict for BertForSequenceClassification:\n",
      "\tUnexpected key(s) in state_dict: \"bert.embeddings.position_ids\". \n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for BertForSequenceClassification:\n\tUnexpected key(s) in state_dict: \"bert.embeddings.position_ids\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdeeppavlov\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m build_model, configs\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Загрузка модели с предобученными весами\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfigs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclassifiers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrusentiment_bert\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Пример текста для классификации\u001b[39;00m\n\u001b[0;32m      7\u001b[0m test_texts \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mЯ люблю программирование.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mЭтот фильм был ужасен.\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\nephelim\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\deeppavlov\\core\\commands\\infer.py:55\u001b[0m, in \u001b[0;36mbuild_model\u001b[1;34m(config, mode, load_trained, install, download)\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m         log\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNo \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msave_path\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m parameter for the \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m component, so \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mload_path\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m will not be renewed\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     53\u001b[0m                     \u001b[38;5;241m.\u001b[39mformat(component_config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclass_name\u001b[39m\u001b[38;5;124m'\u001b[39m, component_config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mref\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUNKNOWN\u001b[39m\u001b[38;5;124m'\u001b[39m))))\n\u001b[1;32m---> 55\u001b[0m component \u001b[38;5;241m=\u001b[39m \u001b[43mfrom_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcomponent_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m component_config:\n\u001b[0;32m     58\u001b[0m     model\u001b[38;5;241m.\u001b[39m_components_dict[component_config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m]] \u001b[38;5;241m=\u001b[39m component\n",
      "File \u001b[1;32mc:\\Users\\nephelim\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\deeppavlov\\core\\common\\params.py:102\u001b[0m, in \u001b[0;36mfrom_params\u001b[1;34m(params, mode, **kwargs)\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmode\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m spec\u001b[38;5;241m.\u001b[39margs \u001b[38;5;241m+\u001b[39m spec\u001b[38;5;241m.\u001b[39mkwonlyargs \u001b[38;5;129;01mor\u001b[39;00m spec\u001b[38;5;241m.\u001b[39mvarkw \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    100\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmode\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m mode\n\u001b[1;32m--> 102\u001b[0m component \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconfig_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    104\u001b[0m     _refs[config_params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m]] \u001b[38;5;241m=\u001b[39m component\n",
      "File \u001b[1;32mc:\\Users\\nephelim\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\deeppavlov\\models\\torch_bert\\torch_transformers_classifier.py:121\u001b[0m, in \u001b[0;36mTorchTransformersClassifierModel.__init__\u001b[1;34m(self, n_classes, pretrained_bert, multilabel, return_probas, attention_probs_keep_prob, hidden_keep_prob, bert_config_file, is_binary, num_special_tokens, **kwargs)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_special_tokens \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    119\u001b[0m     model\u001b[38;5;241m.\u001b[39mresize_token_embeddings(\u001b[38;5;28mlen\u001b[39m(tokenizer) \u001b[38;5;241m+\u001b[39m num_special_tokens)\n\u001b[1;32m--> 121\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nephelim\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\deeppavlov\\core\\models\\torch_model.py:84\u001b[0m, in \u001b[0;36mTorchModel.__init__\u001b[1;34m(self, model, device, optimizer, optimizer_parameters, learning_rate_drop_patience, learning_rate_drop_div, load_before_drop, min_learning_rate, clip_norm, *args, **kwargs)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_learning_rate \u001b[38;5;241m=\u001b[39m min_learning_rate\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclip_norm \u001b[38;5;241m=\u001b[39m clip_norm\n\u001b[1;32m---> 84\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;66;03m# we need to switch to eval mode here because by default it's in `train` mode.\u001b[39;00m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;66;03m# But in case of `interact/build_model` usage, we need to have model in eval mode.\u001b[39;00m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39meval()\n",
      "File \u001b[1;32mc:\\Users\\nephelim\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\deeppavlov\\core\\models\\torch_model.py:144\u001b[0m, in \u001b[0;36mTorchModel.load\u001b[1;34m(self, fname, *args, **kwargs)\u001b[0m\n\u001b[0;32m    142\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mmodule\u001b[38;5;241m.\u001b[39mload_state_dict(model_state)\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 144\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:  \u001b[38;5;66;03m# TODO: remove this try-except after hf models deep update\u001b[39;00m\n\u001b[0;32m    146\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mload_state_dict(optimizer_state)\n",
      "File \u001b[1;32mc:\\Users\\nephelim\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2584\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[1;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[0;32m   2576\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[0;32m   2577\u001b[0m             \u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m   2578\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   2579\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)\n\u001b[0;32m   2580\u001b[0m             ),\n\u001b[0;32m   2581\u001b[0m         )\n\u001b[0;32m   2583\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 2584\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m   2585\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   2586\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)\n\u001b[0;32m   2587\u001b[0m         )\n\u001b[0;32m   2588\u001b[0m     )\n\u001b[0;32m   2589\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for BertForSequenceClassification:\n\tUnexpected key(s) in state_dict: \"bert.embeddings.position_ids\". "
     ]
    }
   ],
   "source": [
    "from deeppavlov import build_model, configs\n",
    "\n",
    "# Загрузка модели с предобученными весами\n",
    "model = build_model(configs.classifiers.rusentiment_bert, download=True)\n",
    "\n",
    "# Пример текста для классификации\n",
    "test_texts = [\"Я люблю программирование.\", \"Этот фильм был ужасен.\"]\n",
    "\n",
    "# Классификация текста\n",
    "predicted_labels = model(test_texts)\n",
    "print(predicted_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'topics_distilbert_base_uncased': 'C:\\\\Users\\\\nephelim\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\deeppavlov\\\\configs\\\\classifiers\\\\topics_distilbert_base_uncased.json', 'insults_kaggle_bert': 'C:\\\\Users\\\\nephelim\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\deeppavlov\\\\configs\\\\classifiers\\\\insults_kaggle_bert.json', 'few_shot_roberta': 'C:\\\\Users\\\\nephelim\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\deeppavlov\\\\configs\\\\classifiers\\\\few_shot_roberta.json', 'rusentiment_bert': 'C:\\\\Users\\\\nephelim\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\deeppavlov\\\\configs\\\\classifiers\\\\rusentiment_bert.json', 'sentiment_twitter': 'C:\\\\Users\\\\nephelim\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\deeppavlov\\\\configs\\\\classifiers\\\\sentiment_twitter.json', 'query_pr': 'C:\\\\Users\\\\nephelim\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\deeppavlov\\\\configs\\\\classifiers\\\\query_pr.json', 'superglue': {'superglue_copa_roberta': 'C:\\\\Users\\\\nephelim\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\deeppavlov\\\\configs\\\\classifiers\\\\superglue\\\\superglue_copa_roberta.json', 'superglue_record_roberta': 'C:\\\\Users\\\\nephelim\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\deeppavlov\\\\configs\\\\classifiers\\\\superglue\\\\superglue_record_roberta.json', 'superglue_wic_bert': 'C:\\\\Users\\\\nephelim\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\deeppavlov\\\\configs\\\\classifiers\\\\superglue\\\\superglue_wic_bert.json', 'superglue_boolq_roberta_mnli': 'C:\\\\Users\\\\nephelim\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\deeppavlov\\\\configs\\\\classifiers\\\\superglue\\\\superglue_boolq_roberta_mnli.json'}, 'rusentiment_convers_distilrubert_2L': 'C:\\\\Users\\\\nephelim\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\deeppavlov\\\\configs\\\\classifiers\\\\rusentiment_convers_distilrubert_2L.json', 'paraphraser_convers_distilrubert_6L': 'C:\\\\Users\\\\nephelim\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\deeppavlov\\\\configs\\\\classifiers\\\\paraphraser_convers_distilrubert_6L.json', 'sentiment_sst_conv_bert': 'C:\\\\Users\\\\nephelim\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\deeppavlov\\\\configs\\\\classifiers\\\\sentiment_sst_conv_bert.json', 'boolqa_rubert': 'C:\\\\Users\\\\nephelim\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\deeppavlov\\\\configs\\\\classifiers\\\\boolqa_rubert.json', 'glue': {'glue_sst2_roberta': 'C:\\\\Users\\\\nephelim\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\deeppavlov\\\\configs\\\\classifiers\\\\glue\\\\glue_sst2_roberta.json', 'glue_wnli_roberta': 'C:\\\\Users\\\\nephelim\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\deeppavlov\\\\configs\\\\classifiers\\\\glue\\\\glue_wnli_roberta.json', 'glue_rte_roberta_mnli': 'C:\\\\Users\\\\nephelim\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\deeppavlov\\\\configs\\\\classifiers\\\\glue\\\\glue_rte_roberta_mnli.json', 'glue_stsb_roberta': 'C:\\\\Users\\\\nephelim\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\deeppavlov\\\\configs\\\\classifiers\\\\glue\\\\glue_stsb_roberta.json', 'glue_rte_cased_bert_torch': 'C:\\\\Users\\\\nephelim\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\deeppavlov\\\\configs\\\\classifiers\\\\glue\\\\glue_rte_cased_bert_torch.json', 'glue_mnli_mm_cased_bert_torch': 'C:\\\\Users\\\\nephelim\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\deeppavlov\\\\configs\\\\classifiers\\\\glue\\\\glue_mnli_mm_cased_bert_torch.json', 'glue_qqp_roberta': 'C:\\\\Users\\\\nephelim\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\deeppavlov\\\\configs\\\\classifiers\\\\glue\\\\glue_qqp_roberta.json', 'glue_mrpc_roberta': 'C:\\\\Users\\\\nephelim\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\deeppavlov\\\\configs\\\\classifiers\\\\glue\\\\glue_mrpc_roberta.json', 'glue_mnli_roberta': 'C:\\\\Users\\\\nephelim\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\deeppavlov\\\\configs\\\\classifiers\\\\glue\\\\glue_mnli_roberta.json', 'glue_mnli_cased_bert_torch': 'C:\\\\Users\\\\nephelim\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\deeppavlov\\\\configs\\\\classifiers\\\\glue\\\\glue_mnli_cased_bert_torch.json', 'glue_qnli_roberta': 'C:\\\\Users\\\\nephelim\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\deeppavlov\\\\configs\\\\classifiers\\\\glue\\\\glue_qnli_roberta.json', 'glue_cola_roberta': 'C:\\\\Users\\\\nephelim\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\deeppavlov\\\\configs\\\\classifiers\\\\glue\\\\glue_cola_roberta.json'}, 'rusentiment_convers_distilrubert_6L': 'C:\\\\Users\\\\nephelim\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\deeppavlov\\\\configs\\\\classifiers\\\\rusentiment_convers_distilrubert_6L.json', 'paraphraser_rubert': 'C:\\\\Users\\\\nephelim\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\deeppavlov\\\\configs\\\\classifiers\\\\paraphraser_rubert.json', 'rusentiment_convers_bert': 'C:\\\\Users\\\\nephelim\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\deeppavlov\\\\configs\\\\classifiers\\\\rusentiment_convers_bert.json', 'paraphraser_convers_distilrubert_2L': 'C:\\\\Users\\\\nephelim\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\deeppavlov\\\\configs\\\\classifiers\\\\paraphraser_convers_distilrubert_2L.json'}\n"
     ]
    }
   ],
   "source": [
    "from deeppavlov import configs\n",
    "\n",
    "# Вывод всех доступных конфигураций\n",
    "print(configs.classifiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('rus_text_classification.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = [(text, label) for text, label in zip(df['text'], df['label'])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Struct' object has no attribute 'bert'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m build_model(\u001b[43mconfigs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclassifiers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbert\u001b[49m, download\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Struct' object has no attribute 'bert'"
     ]
    }
   ],
   "source": [
    "model = build_model(configs.classifiers.bert, download=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
